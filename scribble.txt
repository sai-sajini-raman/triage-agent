import os
import shutil
from datetime import datetime
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import UserMessage
from azure.core.credentials import AzureKeyCredential
from dotenv import load_dotenv

# Load API key from .env file
load_dotenv()  # This loads variables from .env
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN", "")
print("GITHUB_TOKEN loaded:", repr(GITHUB_TOKEN))

client = ChatCompletionsClient(
    endpoint="https://models.github.ai/inference",
    credential=AzureKeyCredential(GITHUB_TOKEN),
)

def call_github_llm(prompt, max_tokens=2048):
    response = client.complete(
        messages=[UserMessage(prompt)],
        model="deepseek/DeepSeek-R1-0528",
        max_tokens=max_tokens,
    )
    return response.choices[0].message.content


if __name__ == "__main__":
    # Insert your prompt here
    prompt = ("xxxxxxxx")

    llm_output = call_github_llm(prompt)

    